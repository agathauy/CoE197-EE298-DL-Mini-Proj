{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import CuDNNLSTM, LSTM, Bidirectional\n",
    "from keras.layers import Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint, History, Callback\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# From stylenet testings \"check piano representation\"\n",
    "import pretty_midi\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import lib.file_util_v2\n",
    "from lib.midi_util_v2 import midi_to_array_one_hot, stylify\n",
    "from mido import MidiFile\n",
    "from random import shuffle\n",
    "\n",
    "import pickle\n",
    "\n",
    "#from lib.midi_util import \n",
    "\n",
    "\n",
    "# The MIDI pitches we use.\n",
    "# PITCHES = range(21,109,1)\n",
    "# OFFSET = 109-21\n",
    "\n",
    "# # The reverse of what is in encoding\n",
    "# PITCHES_MAP = { i : p for i, p in enumerate(PITCHES) }\n",
    "# print(len(PITCHES))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# A state is composed of the order of pitches contained in PITCHES_MAP\n",
    "# state = 3*length of pitches_map\n",
    "# where each pitch_state in a state is composed of [active or not, event, velocity]\n",
    "PITCHES_TO_INDEX = {}\n",
    "INDEX_TO_PITCHES = {}\n",
    "\n",
    "# STATES TO INDICES\n",
    "STATES_TO_INDEX = {}\n",
    "INDEX_TO_STATES = {}\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "######################################################\n",
    "\n",
    "Setting Input and Output Folder\n",
    "\n",
    "######################################################\n",
    "\"\"\"\n",
    "\n",
    "#INPUT_FOLDER = './input/magenta_2013'\n",
    "#OUTPUT_FOLDER = './output/magenta_2013'\n",
    "#INPUT_FOLDER = './input/Bach_Fuga sopra il Magnificat in D minor'\n",
    "#OUTPUT_FOLDER = './output/Bach_Fuga sopra il Magnificat in D minor'\n",
    "# INPUT_FOLDER = 'input/Bach_wv1041a'\n",
    "#INPUT_FOLDER = 'input/Golden_Sun_2'\n",
    "#OUTPUT_FOLDER = 'output/Golden_Sun_2_v0'\n",
    "# OUTPUT_FOLDER = 'output/Bach_wv1041a'\n",
    "\n",
    "INPUT_FOLDER = './data/preprocessed/single_piano/midi_bts_boy_with_luv'\n",
    "OUTPUT_FOLDER = './output/lstm_single_instrument_v3/midi_bts_boy_with_luv'\n",
    "\n",
    "PREPROCESSED_FOLDER =  OUTPUT_FOLDER + '/preprocessed'\n",
    "\n",
    "\n",
    "# INPUT_FOLDER = './input/midi_bts_single_boy_with_luv'\n",
    "# OUTPUT_FOLDER = './output/midi_bts_single_boy_with_luv_input_100'\n",
    "\n",
    "if not os.path.exists(INPUT_FOLDER):\n",
    "    print(\"Input folder: {} does not exist\".format(INPUT_FOLDER))\n",
    "    sys.exit()\n",
    "\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    print(\"Creating folder: {}\".format(OUTPUT_FOLDER))\n",
    "    os.makedirs(OUTPUT_FOLDER)\n",
    "\n",
    "\"\"\"\n",
    "######################################################\n",
    "\n",
    "Custom Training Callbacks\n",
    "\n",
    "Custom callback for generating data as the model trains (so we can view the data immediately)\n",
    "\n",
    "######################################################\n",
    "\"\"\"\n",
    "class ModelCheckpoint_GenerateData(Callback):\n",
    "    \"\"\"Generate data with model every given time period\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filepath, notes, network_input, period=1, verbose=True):\n",
    "        super(ModelCheckpoint_GenerateData, self).__init__()\n",
    "        self.filepath = filepath\n",
    "        self.period = period\n",
    "        self.epochs_since_last_save = 0\n",
    "        self.verbose = verbose\n",
    "        # Data needed for data generation\n",
    "        self.notes = notes\n",
    "        self.network_input = network_input\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.epochs_since_last_save += 1\n",
    "        if self.epochs_since_last_save >= self.period:\n",
    "            self.epochs_since_last_save = 0\n",
    "            filepath = self.filepath.format(epoch=epoch+1, **logs)\n",
    "            # Do something with the model\n",
    "            length_notes =  np.unique(self.notes, axis=0).shape[0]\n",
    "            print('length_notes: ')\n",
    "            #print(length_notes)\n",
    "\n",
    "            print(\"Generating midi and predicting\")\n",
    "            start_time = time.time()\n",
    "            prediction_output, random_seed = generate_notes(self.model, self.notes, self.network_input, length_notes)\n",
    "            #print('prediction_output')\n",
    "            #print(prediction_output)\n",
    "            start_create_time = time.time()\n",
    "            create_midi(prediction_output, filepath, self.notes)\n",
    "            end_time = time.time()\n",
    "            print(\"CREATE MIDI TIME: {}\".format(end_time - start_create_time))\n",
    "            print(\"TOTAL GENERATION TIME ELAPSED: {}\".format(end_time - start_time))\n",
    "            if self.verbose > 0:\n",
    "                 print('\\nEpoch %05d: saving data to %s' % (epoch + 1, filepath))\n",
    "\n",
    "\"\"\"\n",
    "######################################################\n",
    "\n",
    "Data Preprocessing\n",
    "\n",
    "######################################################\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_notes_and_velocities():\n",
    "    \"\"\"\n",
    "        Get all the notes from the midi files\n",
    "\n",
    "        Creates the PITCHES_TO_INDEX and INDEX_TO_PITCHES mapping for the pitch dictionaries\n",
    "\n",
    "        returns the list of \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    global PITCHES_TO_INDEX\n",
    "    global INDEX_TO_PITCHES\n",
    "\n",
    "\n",
    "    notes = np.array([])\n",
    "    velocities = np.array([])\n",
    "\n",
    "\n",
    "    # CREATE PITCHES_MAP, a mapping of unique values\n",
    "    # a dictionary always has unique values\n",
    "\n",
    "    # first count the number of pitches for all files\n",
    "    # for instrument in midi_data.instruments:\n",
    "    #     print(instrument)\n",
    "    #     for i, note in enumerate(instrument.notes):\n",
    "    #         print(note)\n",
    "    #         note_name = pretty_midi.note_number_to_name(note.pitch)\n",
    "    #         print(note_name)\n",
    "    #         print(pretty_midi.note_name_to_number(note_name))\n",
    "    #         if (i > 5):\n",
    "    #             break\n",
    "\n",
    "    list_notes = []\n",
    "    list_mid_data = []\n",
    "    for file in glob.glob(INPUT_FOLDER + \"/*.mid\"):\n",
    "        midi_data = pretty_midi.PrettyMIDI(file)\n",
    "        for instrument in midi_data.instruments:\n",
    "            print(instrument)\n",
    "            for i, note in enumerate(instrument.notes):\n",
    "                #print(note)\n",
    "                #note_name = pretty_midi.note_number_to_name(note.pitch)\n",
    "                list_notes.append(note.pitch)\n",
    "                #list_notes.append(note_name)\n",
    "                #print(pretty_midi.note_name_to_number(note_name))\n",
    "    #print(len(list_notes))\n",
    "    set_notes = set(item for item in list_notes)\n",
    "    num_unique_notes = len(set_notes)\n",
    "    #print(num_unique_notes)\n",
    "\n",
    "    # Create the mappings\n",
    "    for i, item in enumerate(set_notes):\n",
    "        PITCHES_TO_INDEX[item] = i\n",
    "        INDEX_TO_PITCHES[i] = item\n",
    "\n",
    "    #print(len(PITCHES_TO_INDEX))\n",
    "    #print(PITCHES_TO_INDEX)\n",
    "    #print(len(INDEX_TO_PITCHES))\n",
    "    #print(INDEX_TO_PITCHES)\n",
    "    #import pickle\n",
    "\n",
    "    file_path = OUTPUT_FOLDER + '/PITCHES_TO_INDEX.pkl'\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        pickle.dump(PITCHES_TO_INDEX, f)\n",
    "\n",
    "    file_path = OUTPUT_FOLDER + '/INDEX_TO_PITCHES.pkl'\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        pickle.dump(INDEX_TO_PITCHES, f)\n",
    "\n",
    "    list_midi_data = None\n",
    "    # Get the quantized midi to array of each file\n",
    "    for file in glob.glob(INPUT_FOLDER + \"/*.mid\"):\n",
    "\n",
    "        #midi = converter.parse(file)\n",
    "\n",
    "        print(\"Parsing %s\" % file)\n",
    "        #mid_path = os.path\n",
    "        try:\n",
    "            midi_data = pretty_midi.PrettyMIDI(file)\n",
    "            mid = MidiFile(file)\n",
    "        except (KeyError, IOError, IndexError, EOFError, ValueError):\n",
    "            print(\"NAUGHTY\")\n",
    "            break\n",
    "\n",
    "        midi_array = midi_to_array_one_hot(mid, 4, PITCHES_TO_INDEX)\n",
    "        print(\"[MIDI_ARRAY]\")\n",
    "        #print(midi_array)\n",
    "        #print(midi_array.shape)\n",
    "        #test = midi_array.tolist()\n",
    "        #print(test[0])\n",
    "        #print(len(test[0]))\n",
    "        #notes.append(notes, midi_array[:])\n",
    "        #notes = np.concatenate((notes, midi_array), axis=0)\n",
    "        #print(notes[0:5])\n",
    "        #print(notes.shape)\n",
    "\n",
    "        # Add in each song as part of a big sequence.\n",
    "        # These are in effect the list of NON-UNIQUE sequnetial states\n",
    "        if list_midi_data == None:\n",
    "            list_midi_data = midi_array\n",
    "        else:\n",
    "            list_midi_data = np.vstack((list_midi_data, midi_array))\n",
    "        #list_midi_data = np.concatenate((list_midi_data, midi_array), axis=0)\n",
    "        #break\n",
    "\n",
    "    return list_midi_data\n",
    "\n",
    "def prepare_sequences(notes, n_vocab):\n",
    "    \"\"\" \n",
    "        Prepare the sequences used by the Neural Network.\n",
    "        Converts the sequences of states into embeddings based on list of unique states\n",
    "        Returns\n",
    "            network_input\n",
    "            network_output\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    sequence_length = 50\n",
    "    #print(len(notes))\n",
    "    #print(notes.shape)\n",
    "    #print(notes[0])\n",
    "\n",
    "    #n = np.unique(notes, axis=0)\n",
    "    #print(n[0])\n",
    "    #print(n.shape)\n",
    "    #pitchnames = n.tolist()\n",
    "    #print(len(n))\n",
    "    #print(len(pitchnames))\n",
    "    #print(pitchnames[0:5])\n",
    "    print(notes.shape)\n",
    "    temp_notes = notes.tolist()\n",
    "    #print(temp_notes[0:5])\n",
    "    # get all pitch names\n",
    "    #pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "    # create a dictionary to map pitches to integers\n",
    "    #Counter(str(e) for e in li)\n",
    "\n",
    "    #note_to_int = dict((str(note), number) for number, note in enumerate(pitchnames))\n",
    "    #print(\"len(note_to_int)\")\n",
    "    #print(len(note_to_int))\n",
    "    #print(note_to_int[0])\n",
    "    #print(note_to_int)\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    #print(STATES_TO_INDEX)\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(temp_notes) - sequence_length, 1):\n",
    "        sequence_in = temp_notes[i:i + sequence_length]\n",
    "        sequence_out = temp_notes[i + sequence_length]\n",
    "        network_input.append([STATES_TO_INDEX[str(state)] for state in sequence_in])\n",
    "        #print(network_input[i])\n",
    "        #print(len(network_input))\n",
    "        network_output.append(STATES_TO_INDEX[str(sequence_out)])\n",
    "        #print(network_output[i])\n",
    "        #print(len(network_output))\n",
    "\n",
    "    #print(network_input[0])\n",
    "    #print(network_output[0])\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    n_patterns = len(network_input)\n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    #print(network_input.shape)\n",
    "    # normalize input between 0 and 1\n",
    "    network_input = network_input / float(n_vocab)\n",
    "\n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "    #print(network_output.shape)\n",
    "    #print(network_output[0:5])\n",
    "    #print(len(np.unique(network_output, axis=0)))\n",
    "\n",
    "\n",
    "    return (network_input, network_output)\n",
    "\n",
    "\"\"\"\n",
    "######################################################\n",
    "\n",
    "LSTM Network Structure\n",
    "\n",
    "######################################################\n",
    "\"\"\"\n",
    "\n",
    "def create_network(network_input, n_vocab):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(CuDNNLSTM(512,input_shape=(network_input.shape[1], network_input.shape[2]),return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Bidirectional(CuDNNLSTM(512, return_sequences=True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Bidirectional(CuDNNLSTM(512)))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "######################################################\n",
    "\n",
    "Training\n",
    "\n",
    "######################################################\n",
    "\"\"\"\n",
    "\n",
    "def train_network(n_epochs=50):\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
    "\n",
    "    global STATES_TO_INDEX\n",
    "    global INDEX_TO_STATES\n",
    "\n",
    "    # Get list of all states from midi files\n",
    "    notes = get_notes_and_velocities()\n",
    "\n",
    "    # print(notes.shape)\n",
    "    #print(notes[0])\n",
    "\n",
    "    # Get the number of unique instances\n",
    "    # So we can create an embedding!\n",
    "    n = np.unique(notes, axis=0)\n",
    "    # print(n.shape)\n",
    "\n",
    "    # The number of unique states/\"notes\"\n",
    "    n_vocab = n.shape[0]\n",
    "\n",
    "    for i, item in enumerate(n):\n",
    "        STATES_TO_INDEX[str(item.tolist())] = i\n",
    "        INDEX_TO_STATES[i] = item.tolist()\n",
    "\n",
    "    # print(len(STATES_TO_INDEX))\n",
    "    # print(len(INDEX_TO_STATES))\n",
    "    # print(INDEX_TO_STATES[0]) # match a\n",
    "    # print(INDEX_TO_STATES[1])\n",
    "    # print(str(INDEX_TO_STATES[0])) # match a\n",
    "    # print(STATES_TO_INDEX[str(INDEX_TO_STATES[0])])\n",
    "    # print(STATES_TO_INDEX[str(INDEX_TO_STATES[1])])\n",
    "\n",
    "\n",
    "    file_path = OUTPUT_FOLDER + '/STATES_TO_INDEX.pkl'\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        pickle.dump(STATES_TO_INDEX, f)\n",
    "\n",
    "    file_path = OUTPUT_FOLDER + '/INDEX_TO_STATES.pkl'\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        pickle.dump(INDEX_TO_STATES, f)\n",
    "\n",
    "\n",
    "    # Convert the states into numerical input!\n",
    "    # Base this on their encodings given unique states\n",
    "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
    "\n",
    "    #print(network_input[0])\n",
    "    # Set up the model\n",
    "    model = create_network(network_input, n_vocab)\n",
    "    history = History()\n",
    "\n",
    "    \n",
    "\n",
    "    mc = ModelCheckpoint('./' + OUTPUT_FOLDER + '/LSTMmodel_{epoch:08d}.h5', \n",
    "                                     save_weights_only=True, period=10)\n",
    "    mc_gd = ModelCheckpoint_GenerateData('./' + OUTPUT_FOLDER + '/out_{epoch:08d}', \\\n",
    "        period=10,verbose=True, notes=notes, network_input=network_input)\n",
    "    try:\n",
    "\n",
    "        model.summary()\n",
    "        model.fit(network_input, network_output, epochs=n_epochs, batch_size=64, callbacks=[history,mc, mc_gd])\n",
    "        model.save('./' + OUTPUT_FOLDER + '/LSTMmodel.h5')\n",
    "\n",
    "        # Use the model to generate a midi\n",
    "        prediction_output, random_seed = generate_notes(model, notes, network_input, len(n_vocab))\n",
    "        #create_midi(prediction_output, 'pokemon_midi')\n",
    "        file_name = './' + OUTPUT_FOLDER + '/out_' + str(n_epochs)\n",
    "        create_midi(prediction_output, file_name, notes)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Keyboard interrupt\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"error in train_network\")\n",
    "\n",
    "    # Plot the model losses\n",
    "    pd.DataFrame(history.history).plot()\n",
    "    plt.savefig('./' + OUTPUT_FOLDER + '/LSTM_Loss_per_Epoch.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "######################################################\n",
    "\n",
    "Generation of prediction to MIDI\n",
    "\n",
    "######################################################\n",
    "\"\"\"\n",
    "\n",
    "def generate_notes(model, notes, network_input, n_vocab, random_seed=None):\n",
    "    \"\"\"\n",
    "        Generate notes from the neural network based on a sequence of notes \n",
    "\n",
    "        prediction_output will be a series of states of format [123, 0, 290, ...] and need to be\n",
    "        converted back to state form with INDEX_TO_STATES\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    # pick a random sequence from the input as a starting point for the prediction\n",
    "    #pitchnames = sorted(set(item for item in notes))\n",
    "    #PITCHES_MAP\n",
    "\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "\n",
    "    # n = np.unique(notes, axis=0)\n",
    "    # #print(n[0])\n",
    "    # print(n.shape)\n",
    "    # pitchnames = n.tolist()\n",
    "\n",
    "    start = np.random.randint(0, len(network_input)-1)\n",
    "\n",
    "    # int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    pattern = network_input[start]\n",
    "    print(\"Starting pattern: \")\n",
    "    # print(pattern)\n",
    "    # print(start)\n",
    "    prediction_output = []\n",
    "\n",
    "    # generate 2048 notes\n",
    "    for note_index in range(500):\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        #print('prediction_input shape:')\n",
    "        #print(prediction_input.shape)\n",
    "        #print(prediction_input)\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "        #print(\"model's prediction\")\n",
    "        #print(prediction)\n",
    "        index = np.argmax(prediction)\n",
    "        #print(\"max index: \")\n",
    "        #print(index)\n",
    "        result = index\n",
    "\n",
    "        prediction_output.append(result)\n",
    "\n",
    "        pattern = np.append(pattern,index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "\n",
    "    return (prediction_output, random_seed)\n",
    "\n",
    "def create_midi(prediction_output, filename, notes):\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "        from the notes \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "    print(\"here in create_midi\")\n",
    "    piano_c_chord = pretty_midi.PrettyMIDI()\n",
    "    piano = pretty_midi.Instrument(program=0, name='Piano')\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    max_len = len(prediction_output)\n",
    "    print(\"max_len\")\n",
    "    print(max_len)\n",
    "    print(prediction_output)\n",
    "    on_list = []\n",
    "    on_list_pos_only = []\n",
    "    init = 0\n",
    "    offset = 0\n",
    "\n",
    "    #print(INDEX_TO_STATES)\n",
    "\n",
    "\n",
    "    # this signifies a LIST OF STATES\n",
    "    # where each number in the list represents a list\n",
    "    for i, state_num in enumerate(prediction_output):\n",
    "        #print(pattern)\n",
    "        #print(len(pattern))\n",
    "        #print(state_num)\n",
    "        pattern = INDEX_TO_STATES[state_num]\n",
    "\n",
    "        # i = tick, can be converted into time\n",
    "        # note on [1,1]\n",
    "        # note sustained [0, 1]\n",
    "        # note off [0, 0]\n",
    "        arr_pattern = np.array(pattern)\n",
    "        #print('pattern')\n",
    "        #print(arr_pattern)\n",
    "        #print(arr_pattern.shape)\n",
    "        indices = np.where(arr_pattern != 0)[0]\n",
    "        #print(indices)\n",
    "        indices = indices.tolist()\n",
    "\n",
    "        #print(indices)\n",
    "        # check all ones\n",
    "\n",
    "        for _, pos in enumerate(indices):\n",
    "            # look at the value of the indices\n",
    "\n",
    "            # Check for new notes\n",
    "            # Check if note is on\n",
    "            if (pos % 3) == 0:\n",
    "                # in a  position of interval of 3\n",
    "                if not pos in on_list_pos_only:\n",
    "                    # this is not a sustain\n",
    "                    # append [index of state, tick, velocity based on state]\n",
    "                    on_list.append([pos, i, INDEX_TO_STATES[pos + 2]])\n",
    "                    on_list_pos_only.append(pos)\n",
    "            else:\n",
    "                # odd number position, possibly a velocity or note state\n",
    "                # check for sustain/consider as new note if it appears\n",
    "                if init == 1:\n",
    "                    for j, on in enumerate(on_list):\n",
    "                        if on[0] == (pos - 1):\n",
    "                            # for sustain\n",
    "                            on_list[j][1] = on_list[j][1] + 1 # add another tick to the sustain\n",
    "                            break\n",
    "                        elif on[0] == (pos -2):\n",
    "                            # for velocity\n",
    "                            on_list[j][2] = 0\n",
    "\n",
    "            # to always active init after first loop\n",
    "            init = 1\n",
    "\n",
    "        # Check if anything from the on_list is now off\n",
    "        for _, on in enumerate(on_list):\n",
    "            if (on[0] not in indices):\n",
    "                # check if not sustain\n",
    "                if ((on[0] + 1) not in indices):\n",
    "                    # Remove the note and add to midi file\n",
    "                    # constant velocity for now\n",
    "                    start_tick = on[1]\n",
    "                    end_tick = i\n",
    "                    #total_ticks = end_tick - start_tick\n",
    "                    start_time = start_tick * 0.5\n",
    "                    end_time = end_tick * 0.5\n",
    "                    print(\"Appending note: {}\".format(INDEX_TO_PITCHES[int(on[0]/3)]))\n",
    "                    note = pretty_midi.Note(velocity=on[2], pitch=INDEX_TO_PITCHES[int(on[0]/3)], start=start_time, end=end_time)\n",
    "                    # add it to our piano \n",
    "                    piano.notes.append(note)\n",
    "\n",
    "\n",
    "                    # remove the note\n",
    "                    on_list_pos_only.remove(on[0])\n",
    "                    on_list.remove(on)\n",
    "\n",
    "\n",
    "    # Add the piano instrument to the PrettyMIDI object\n",
    "    piano_c_chord.instruments.append(piano)\n",
    "    # Write out the MIDI data\n",
    "    midi_name = filename + '.mid'\n",
    "    piano_c_chord.write(midi_name)\n",
    "\n",
    "    # midi_stream = stream.Stream(output_notes)\n",
    "    # midi_stream.write('midi', fp='{}.mid'.format(filename))\n",
    "\n",
    "def generate_given_model_path(file_path, random_seed=None):\n",
    "    \"\"\" Generate a song given the file path to the model \n",
    "        and an optional random seed \"\"\"\n",
    "    global INDEX_TO_STATES\n",
    "    global STATES_TO_INDEX\n",
    "\n",
    "    global PITCHES_TO_INDEX\n",
    "    global INDEX_TO_PITCHES\n",
    "\n",
    "    file_path = OUTPUT_FOLDER + '/INDEX_TO_STATES.pkl'\n",
    "    INDEX_TO_STATES = pickle.load( open( file_path, \"rb\" ) )\n",
    "\n",
    "    file_path = OUTPUT_FOLDER + '/STATES_TO_INDEX.pkl'\n",
    "    STATES_TO_INDEX = pickle.load( open( file_path, \"rb\" ) )\n",
    "\n",
    "    file_path = OUTPUT_FOLDER + '/PITCHES_TO_INDEX.pkl'\n",
    "    PITCHES_TO_INDEX = pickle.load( open( file_path, \"rb\" ) )\n",
    "\n",
    "    file_path = OUTPUT_FOLDER + '/INDEX_TO_PITCHES.pkl'\n",
    "    INDEX_TO_PITCHES = pickle.load( open( file_path, \"rb\" ) )\n",
    "\n",
    "    notes = get_notes_and_velocities()\n",
    "\n",
    "\n",
    "    n = np.unique(notes, axis=0)\n",
    "    print(n.shape)\n",
    "\n",
    "    n_vocab = n.shape[0]\n",
    "\n",
    "    # Convert notes into numerical input\n",
    "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
    "\n",
    "\n",
    "    model = create_network(network_input, n_vocab)\n",
    "    model.load_weights(file_path)\n",
    "\n",
    "\n",
    "    # Use the model to generate a midi\n",
    "    prediction_output, rs = generate_notes(model, notes, network_input, n_vocab, random_seed)\n",
    "    #create_midi(prediction_output, 'pokemon_midi')\n",
    "    file_name = './' + OUTPUT_FOLDER + '/out_rand_' + str(rs)\n",
    "    create_midi(prediction_output, file_name, notes)\n",
    "    print(file_name)\n",
    "\n",
    "    return file_name\n",
    "\n",
    "\n",
    "\n",
    "def continue_training_network(start_epoch, end_epoch):\n",
    "    global INDEX_TO_STATES\n",
    "    global STATES_TO_INDEX\n",
    "\n",
    "    global PITCHES_TO_INDEX\n",
    "    global INDEX_TO_PITCHES\n",
    "\n",
    "    file_path = OUTPUT_FOLDER + '/INDEX_TO_STATES.pkl'\n",
    "    INDEX_TO_STATES = pickle.load( open( file_path, \"rb\" ) )\n",
    "\n",
    "    file_path = OUTPUT_FOLDER + '/STATES_TO_INDEX.pkl'\n",
    "    STATES_TO_INDEX = pickle.load( open( file_path, \"rb\" ) )\n",
    "\n",
    "    file_path = OUTPUT_FOLDER + '/PITCHES_TO_INDEX.pkl'\n",
    "    PITCHES_TO_INDEX = pickle.load( open( file_path, \"rb\" ) )\n",
    "\n",
    "    file_path = OUTPUT_FOLDER + '/INDEX_TO_PITCHES.pkl'\n",
    "    INDEX_TO_PITCHES = pickle.load( open( file_path, \"rb\" ) )\n",
    "\n",
    "    # Get list of all states from midi files\n",
    "    notes = get_notes_and_velocities()\n",
    "\n",
    "    print(notes.shape)\n",
    "    print(notes[0])\n",
    "\n",
    "    # Get the number of unique instances\n",
    "    # So we can create an embedding!\n",
    "    n = np.unique(notes, axis=0)\n",
    "    print(n.shape)\n",
    "\n",
    "    # The number of unique states/\"notes\"\n",
    "    n_vocab = n.shape[0]\n",
    "\n",
    "\n",
    "    print(len(STATES_TO_INDEX))\n",
    "    print(len(INDEX_TO_STATES))\n",
    "    print(INDEX_TO_STATES[0]) # match a\n",
    "    print(INDEX_TO_STATES[1])\n",
    "    print(str(INDEX_TO_STATES[0])) # match a\n",
    "    print(STATES_TO_INDEX[str(INDEX_TO_STATES[0])])\n",
    "    print(STATES_TO_INDEX[str(INDEX_TO_STATES[1])])\n",
    "\n",
    "\n",
    "    # Convert the states into numerical input!\n",
    "    # Base this on their encodings given unique states\n",
    "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
    "\n",
    "    #print(network_input[0])\n",
    "    # Set up the model\n",
    "    model = create_network(network_input, n_vocab)\n",
    "    history = History()\n",
    "\n",
    "\n",
    "    # Load from previous file!\n",
    "    file_path = OUTPUT_FOLDER + \"/LSTMmodel_{:08d}.h5\".format(start_epoch)\n",
    "    model.load_weights(file_path)\n",
    "\n",
    "\n",
    "\n",
    "    mc = ModelCheckpoint('./' + OUTPUT_FOLDER + '/LSTMmodel_start_' + str(start_epoch) + \"_{epoch:08d}.h5\", \n",
    "                                     save_weights_only=True, period=10)\n",
    "    mc_gd = ModelCheckpoint_GenerateData('./' + OUTPUT_FOLDER + '/out_start_' + str(start_epoch) + '_{epoch:08d}', \\\n",
    "        period=10,verbose=True, notes=notes, network_input=network_input)\n",
    "\n",
    "    n_epochs = end_epoch - start_epoch\n",
    "    try:\n",
    "\n",
    "        model.summary()\n",
    "        model.fit(network_input, network_output, epochs=n_epochs, batch_size=64, callbacks=[history,mc, mc_gd])\n",
    "        model.save('./' + OUTPUT_FOLDER + '/LSTMmodel.h5')\n",
    "\n",
    "        # Use the model to generate a midi\n",
    "        prediction_output, random_seed = generate_notes(model, notes, network_input, len(n_vocab))\n",
    "        #create_midi(prediction_output, 'pokemon_midi')\n",
    "        file_name = './' + OUTPUT_FOLDER + '/out_' + str(n_epochs)\n",
    "        create_midi(prediction_output, file_name, notes)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Keyboard interrupt\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"error in continue train_network\")\n",
    "\n",
    "    # Plot the model losses\n",
    "    pd.DataFrame(history.history).plot()\n",
    "    plt.savefig('./' + OUTPUT_FOLDER + '/LSTM_Loss_per_Epoch.png')\n",
    "    plt.close()\n",
    "\n",
    "\"\"\"\n",
    "######################################################\n",
    "\n",
    "Main\n",
    "\n",
    "######################################################\n",
    "\"\"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        train_network(500)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Error in main\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Total time elapsed: {}\".format(end_time - start_time))\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     start_time = time.time()\n",
    "#     try:\n",
    "#         #train_network(500)\n",
    "#         start_epoch = 140\n",
    "#         end_epoch = 500\n",
    "#         continue_training_network(start_epoch, end_epoch)\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         print(\"Error in main\")\n",
    "\n",
    "#     end_time = time.time()\n",
    "#     print(\"Total time elapsed: {}\".format(end_time - start_time))\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     #model_path = \"/home/agatha/Documents/EE298z/miniproj-2/prelim/music_generation_lstm/output/lstm_single_instrument_v2/midi_bts_boy_with_luv/LSTMmodel_00000100.h5\"\n",
    "#     model_path = \"./output/lstm_single_instrument_v3/midi_bts_boy_with_luv/LSTMmodel_00000010.h5\"\n",
    "#     start_time = time.time()\n",
    "\n",
    "#     generate_given_model_path(model_path, random_seed=1000)\n",
    "\n",
    "#     end_time = time.time()\n",
    "#     print(\"Total time elapsed: {}\".format(end_time - start_time))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
