{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Music gereration firth Keras and TensorFlow backend\n",
    "\n",
    "Plan was simple:\n",
    "1. Read midi file, convert it to matrix of features\n",
    "2. Create simple model with Keras and LSTM to learn the pattern\n",
    "3. Use subsample of initial midi file as a input for model to generate pure art\n",
    "4. Save prediction from model to midi file\n",
    ".\n",
    ".\n",
    ".\n",
    "5. PROFIT\n",
    "\n",
    "<i> For disclamer: I've been using my old Dell Laptop with no GPU support</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import mido\n",
    "from mido import MidiFile, MidiTrack, Message\n",
    "from keras.layers import LSTM, Dense, Activation, Dropout, Flatten\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read midi file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = MidiFile('Samples/Nintendo_-_Pokemon_Fire_Red_Route_1_Piano_Cover_Hard_Version.mid') \n",
    "notes = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract notes sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = []\n",
    "for msg in mid:\n",
    "    if not msg.is_meta and msg.channel == 0 and msg.type == 'note_on':\n",
    "        data = msg.bytes()\n",
    "        notes.append(data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply min-max scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agatha/miniconda3/envs/ee298z/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaler.fit(np.array(notes).reshape(-1,1))\n",
    "notes = list(scaler.transform(np.array(notes).reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare features for training and data subsample for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM layers requires that data must have a certain shape\n",
    "# create list of lists fist\n",
    "notes = [list(note) for note in notes]\n",
    "\n",
    "# subsample data for training and prediction\n",
    "X = []\n",
    "y = []\n",
    "# number of notes in a batch\n",
    "n_prev = 30\n",
    "for i in range(len(notes)-n_prev):\n",
    "    X.append(notes[i:i+n_prev])\n",
    "    y.append(notes[i+n_prev])\n",
    "# save a seed to do prediction later\n",
    "X_test = X[-300:]\n",
    "X = X[:-300]\n",
    "y = y[:-300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Made sequential model with several layers, use LSTM as it time dependent data\n",
    "\n",
    "I also whant to save checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(n_prev, 1), return_sequences=True))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(LSTM(128, input_shape=(n_prev, 1), return_sequences=True))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(LSTM(64, input_shape=(n_prev, 1), return_sequences=False))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(loss='mse', optimizer=optimizer)\n",
    "filepath=\"./Checkpoints/checkpoint_model_{epoch:02d}.hdf5\"\n",
    "model_save_callback = ModelCheckpoint(filepath, monitor='val_acc', \n",
    "                                      verbose=1, save_best_only=False, \n",
    "                                      mode='auto', period=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train your model.\n",
    "It might take a while, I was waiting for 1 hour with just 5 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "12770/12770 [==============================] - 46s 4ms/step - loss: 0.0522\n",
      "Epoch 2/5\n",
      "12770/12770 [==============================] - 43s 3ms/step - loss: 0.0472\n",
      "Epoch 3/5\n",
      "12770/12770 [==============================] - 43s 3ms/step - loss: 0.0449\n",
      "Epoch 4/5\n",
      "12770/12770 [==============================] - 43s 3ms/step - loss: 0.0427\n",
      "Epoch 5/5\n",
      "12770/12770 [==============================] - 43s 3ms/step - loss: 0.0356\n",
      "\n",
      "Epoch 00005: saving model to ./Checkpoints/checkpoint_model_05.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa0da3e8400>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(X), np.array(y), 32, 5, verbose=1, callbacks=[model_save_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(np.array(X_test))\n",
    "prediction = np.squeeze(prediction)\n",
    "prediction = np.squeeze(scaler.inverse_transform(prediction.reshape(-1,1)))\n",
    "prediction = [int(i) for i in prediction]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save your result to new midi file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = MidiFile()\n",
    "track = MidiTrack()\n",
    "t = 0\n",
    "for note in prediction:\n",
    "    # 147 means note_on\n",
    "    # 67 is velosity\n",
    "    note = np.asarray([147, note, 67])\n",
    "    bytes = note.astype(int)\n",
    "    msg = Message.from_bytes(bytes[0:3])\n",
    "    t += 1\n",
    "    msg.time = t\n",
    "    track.append(msg)\n",
    "mid.tracks.append(track)\n",
    "mid.save('LSTM_music.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just listen to it. The result is surreal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
